{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\"> ![Logo](https://www.ups.edu.ec/ups_portal-theme/images/ups/home/logo-ups-home.png)\n",
    "# <div align=\"center\">  kNN Classification of members of congress using similarity algorithms in Neo4j\n",
    "## Materia:\n",
    "### <div align=\"center\"> Sistemas Expertos \n",
    "## Docente:\n",
    "### <div align=\"center\"> Ing. Diego Quisis\n",
    "## Estudiante\n",
    "### <div align=\"center\"> Ricardo Vinicio Jara Jara\n",
    "\n",
    "## <div align=\"center\">KNN\n",
    "### k-NN es un tipo de aprendizaje basado en instancias,o aprendizaje diferido,donde la función solo se aproxima localmente y todo el cálculo se aplaza hasta la evaluación de la función. Tanto para la clasificación como para la regresión, una técnica útil puede ser asignar pesos a las contribuciones de los vecinos, de modo que los vecinos más cercanos contribuyan más a la media que a los más distantes. Por ejemplo, un esquema de ponderación común consiste en dar a cada vecino un peso de 1/d, donde d es la distancia al vecino. Los vecinos se toman de un conjunto de objetos para los que se conoce la clase (para la clasificación k-NN) o el valor de propiedad del objeto (para la regresión k-NN). Esto se puede considerar como el conjunto de entrenamiento para el algoritmo, aunque no se requiere ningún paso de entrenamiento explícito.\n",
    "    \n",
    "![grafo](https://i1.wp.com/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2014/09/k-Nearest-Neighbors-algorithm.png?resize=816%2C9999&ssl=1)   \n",
    "## <div align=\"center\"> Creacion de Nodos \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOAD CSV FROM \"http://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data\" as row\n",
    "CREATE (p:Person)\n",
    "SET p.class = row[0],\n",
    "    p.features = row[1..];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nodos](https://raw.githubusercontent.com/RicardoVinicioJara/IMG/master/votacios1.png) \n",
    "\n",
    "- Contar Resultados [2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (n:Person) \n",
    "WHERE \"?\" in n.features\n",
    "RETURN count(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Votos perdidos [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (p:Person)\n",
    "WHERE '?' in p.features\n",
    "WITH p,apoc.coll.occurrences(p.features,'?') as missing\n",
    "RETURN missing,count(*) as times ORDER BY missing ASC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nodos](https://raw.githubusercontent.com/RicardoVinicioJara/IMG/master/votaciones2.png) \n",
    "\n",
    "- Excluiremos de nuestro análisis posterior a los que no votaron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (p:Person)\n",
    "WITH p,apoc.coll.occurrences(p.features,'?') as missing\n",
    "WHERE missing > 6\n",
    "DELETE p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hay tres valores posibles en los conjuntos de características. Los mapearemos de la siguiente manera:\n",
    "\n",
    "- \"y\" a 1\n",
    "- \"n\" a 0\n",
    "- \"?\" a 0,5\n",
    "\n",
    "#### Transformar a vector de entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (n:Person)\n",
    "UNWIND n.features as feature\n",
    "WITH n,collect(CASE feature WHEN 'y' THEN 1\n",
    "                            WHEN 'n' THEN 0\n",
    "                            ELSE 0.5 END) as feature_vector\n",
    "SET n.feature_vector = feature_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nodos](https://raw.githubusercontent.com/RicardoVinicioJara/IMG/master/votaciones3.png) \n",
    "\n",
    "# Algoritmo clasificador kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCH (test:Test)\n",
    "WITH test,test.feature_vector as feature_vector\n",
    "CALL apoc.cypher.run('MATCH (training:Training)\n",
    "    WITH training, gds.alpha.similarity.euclideanDistance($feature_vector, training.feature_vector) AS similarity\n",
    "    ORDER BY similarity ASC LIMIT 3\n",
    "    RETURN collect(training.class) as classes',\n",
    "    {feature_vector:feature_vector}) YIELD value\n",
    "WITH test.class as class, apoc.coll.sortMaps(apoc.coll.frequencies(value.classes), '^count')[-1].item as predicted_class\n",
    "WITH sum(CASE when class = predicted_class THEN 1 ELSE 0 END) as correct_predictions, count(*) as total_predictions\n",
    "RETURN correct_predictions,total_predictions, correct_predictions / toFloat(total_predictions) as ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![nodos](https://raw.githubusercontent.com/RicardoVinicioJara/IMG/master/votaciones5.png) \n",
    "\n",
    "## Conclusiones\n",
    "Este método visto anteriormente no ayuda para hacer una clasificación binaria, ya que el algoritmo toma la mayoría de las clases de vecinos y los puede ir puntuando de acuerdo con si similitud. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
